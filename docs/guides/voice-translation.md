# 视频翻译全流程实战指南

> 适用对象：首次接触 PyVideoTrans 的新人用户，亦适用于需要掌握专业工作流的团队成员。

## 1. 使用场景概览

| 场景 | 目标 | 典型输出 |
|------|------|-----------|
| 单个视频英译中 | 为英文教学/访谈视频制作中文字幕和中文配音 | 搭载中文字幕及中文配音的 MP4 视频，同时保留字幕文件 |
| 批量课程本地化 | 批量转换多段英文培训视频 | 批量生成配音音轨 + 中英文对照字幕 |
| 字幕后期润色 | 已有英文字幕，需翻译并合成中文配音 | 翻译后的字幕与匹配的中文语音包 |
| 内容剪辑与再创作 | 提取英文语音内容，重写中文脚本并重新配音 | 中文文本与配音音频，后续可导入剪辑软件 |

## 2. 环境准备

1. **安装程序**  
   - Windows 用户：直接从 [Releases](../../README.md#-快速开始) 下载最新打包版本，解压后运行 `sp.exe`。  
   - macOS / Linux 用户：参考 [安装指南](installation.md) 中对应章节，完成依赖安装与虚拟环境配置。

2. **准备 FFmpeg 与音频库**  
   - Windows 发行包自带；源码部署时请参阅 [安装指南](installation.md#模组下载) 中的系统依赖部分。  
   - macOS/Linux 用户可通过 Homebrew/apt 安装 `ffmpeg` 与 `libsndfile`。

3. **下载语音识别模型**  
   - 首选 Faster-Whisper `small` 或 `medium` 模型。详见 [模型下载指南](model-download.md)。  
   - 将解压后的模型放入项目根目录下的 `models/` 文件夹。

4. **准备翻译与语音服务凭据**  
   - 如需在线翻译或语音合成，请先在 [服务配置](../providers/openai.md) 系列文档中完成 API Key 配置。  
   - 若需完全离线，可在程序设置里选择本地模型或离线翻译选项。

## 3. 首次一键翻译操作

1. **启动 PyVideoTrans**  
   - Windows：双击 `sp.exe`。  
   - macOS/Linux：在虚拟环境中执行 `python sp.py`。

2. **导入英文视频**  
   - 在 GUI 顶部的“文件选择”区域点击“选择视频”，支持 MP4、MOV、MKV 等格式。

3. **设置语言**  
   - 源语言选择 `English`；目标语言选择 `Chinese (Simplified)`。

4. **选择模型与渠道**  
   - 自动识别：选择已下载的 Faster-Whisper 模型。  
   - 文本翻译：若可联网，推荐使用 DeepL 或 ChatGPT；离线场景选择内置翻译。  
   - 语音合成：在 TTS 渠道中选择 `Microsoft Edge TTS` 或 `Azure TTS`，并挑选合适的中文音色。

5. **配置输出**  
   - 指定输出目录与文件名前缀。  
   - 勾选“保留原声轨”可保留原始英文音频，适合制作双语轨道。

6. **高级选项（可选）**  
   - 启用“背景音乐分离”以保留背景音乐。  
   - 调整“配音语速”“音量平衡”以匹配原视频节奏。

7. **开始处理**  
   - 点击“开始翻译”，观察进度条。流程包含：语音识别 → 文本翻译 → 语音合成 → 视频合成。  
   - 完成后在输出目录中检查生成的视频、字幕与音频文件。

## 4. 深入功能详解

### 4.1 输入文件准备
- 建议对原视频进行简单降噪或音量均衡，以提升识别准确率。
- 对超长视频可先分段处理，后续使用“媒体文件合并”功能拼接。

### 4.2 语音识别模型选择

| 模型 | 处理速度 | 推荐场景 | 备注 |
|------|----------|----------|------|
| `tiny` / `base` | 很快 | 预览、播客 | 精度一般，长句易出错 |
| `small` | 平衡 | 一般课程、访谈 | 推荐默认选择 |
| `medium` | 略慢 | 术语较多、口音复杂内容 | 需要充足内存 |
| `large-v3` | 最慢 | 高质量纪录片、配音级项目 | 建议 GPU/MPS 加速 |

### 4.3 翻译服务配置
- **DeepL**：中文润色优秀，适合对话类内容。需在设置中填入 DeepL API Key。  
- **ChatGPT / OpenAI**：可根据上下文给出自然译文，适合需保留语气的场景。  
- **Gemini / DeepSeek**：提供多样化风格翻译，可在 `providers/` 目录查阅配置步骤。  
- **离线翻译**：无需联网，但应对复杂句子能力有限，建议后期人工审校。

### 4.4 语音合成（TTS）
- **Edge TTS**：免费易用，支持大量中文音色，可在程序内直接选择。
- **Azure TTS**：专业级音质，支持角色克隆与情绪控制；需在“服务配置”中填入 `key` 与 `region`。
- **OpenAI / ElevenLabs**：适合追求极致自然度的项目，成本较高。
- **本地 SoVITS**：用于克隆特定音色，适合品牌化配音，但配置复杂。

### 4.5 音频混合与字幕
- **配音音量**：建议配音-原声比例为 1:0.4，既能突出中文，又保留背景氛围。
- **时间轴对齐**：若出现偏移，可在字幕编辑器中批量微调时间轴，或重新勾选“对齐原声”后再处理。
- **字幕格式**：默认输出 SRT，可在“高级设置”中追加 ASS/VTT 格式。

## 5. 批量与自动化

### 5.1 批量任务
1. 在“批量任务”页面选择需翻译的视频或字幕文件。  
2. 配置统一的模型、翻译和 TTS 渠道。  
3. 启动后程序会逐个处理，并在输出目录按文件名生成结果。

### 5.2 命令行（CLI）
- 使用 `python cli.py --help` 查看参数。  
- 示例：
  ```bash
  python cli.py \
    --input sample.mp4 \
    --src_lang en \
    --dst_lang zh \
    --whisper_model small \
    --translator deepl \
    --tts edge
  ```

### 5.3 本地 API
- 启动：`python api.py --port 9011`。  
- 翻译接口示例：
  ```bash
  curl -X POST "http://127.0.0.1:9011/trans_video" \
       -F "file=@sample.mp4" \
       -F "src_lang=en" \
       -F "dst_lang=zh" \
       -F "translator=deepl" \
       -F "tts=edge"
  ```
- 返回内容包含任务 ID，可用于查询进度或下载输出物。

## 6. 推荐配置表

| 硬件条件 | Whisper 模型 | 翻译渠道 | TTS 渠道 | 备注 |
|----------|---------------|----------|----------|------|
| 低配笔记本 (8GB RAM, 无独显) | `base` | 离线翻译 / DeepSeek-Lite | Edge TTS | 适合小型项目，处理速度较慢 |
| 主流办公本 (16GB RAM, RTX 3050) | `small` | DeepL / ChatGPT (gpt-4o-mini) | Azure TTS | 平衡速度与质量，适合常规视频 |
| 高性能工作站 (32GB RAM, RTX 4090) | `large-v3` | DeepL Pro / GPT-4o | ElevenLabs / Azure 高级音色 | 大型课程、本地化团队推荐 |
| Apple Silicon (M2 Pro) | `medium` (MPS 加速) | DeepL / Gemini | Edge TTS | 需启用 MPS 与 Metal 支持 |

## 7. 质量保障流程

1. **脚本审校**：导出翻译文本（可从字幕文件获取），由双语人员审阅关键片段。
2. **音频校准**：确认配音语速与情绪与原声匹配；必要时调整 TTS 参数。
3. **视频检查**：核对字幕位置、时间轴、字体。对需要品牌化的项目，可使用 ASS 样式模板。
4. **终版导出**：保存项目配置，以便批量复用；建议保留原始录入文件和处理日志。

## 8. 常见问题排查

| 症状 | 可能原因 | 解决建议 |
|------|----------|-----------|
| 识别准确率低 | 背景噪音大、模型过小 | 预处理音频，改用 `medium` / `large` 模型 |
| 翻译风格不统一 | 混用不同翻译渠道 | 在同一项目中固定翻译服务，或启用术语表 |
| 配音不同步 | 视频帧率异常 / 字幕时间轴漂移 | 在“高级设置”中勾选“时间轴重采样”，或手动微调字幕 |
| 输出视频无声 | 未勾选“保留配音音轨” / TTS 渠道调用失败 | 检查日志 `logs/app-log-*.txt`，验证 API Key 与网络 |
| GPU 不工作 | CUDA 驱动缺失 / MPS 未启用 | 重新安装对应驱动，查看 [安装指南](installation.md#gpu-加速配置) |
| 批量任务中断 | 某文件格式不兼容 | 逐个检查文件，确保编码正常；必要时转码为 H.264 + AAC |

## 9. 最佳实践提醒

- 为每个项目建立固定目录结构（`source/`、`output/`、`temp/`、`backup/`）。
- 在批量处理前，先用短片段验证参数组合。
- 定期清理 `temp` 目录与模型缓存，保持磁盘充足。
- 对于关键视频，建议人工复核并使用专业音频软件进行最终混音。

## 10. 参考资料

- [用户使用指南](user-guide.md)
- [模型下载指南](model-download.md)
- [服务配置文档](../providers/openai.md)
- [API 文档](../api/api.md)
- [源码导读规划](../internals/index.md)

> 完整掌握上述流程后，即可在团队中建立标准化的英译中视频生产线，实现从单视频到批量内容的高质量交付。